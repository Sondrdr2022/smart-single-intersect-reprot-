% =========================
% CHƯƠNG 3
% =========================
\chapter{Tổng quan tài liệu}

\section{Phương pháp điều khiển giao thông truyền thống}

Các hệ thống điều khiển tín hiệu giao thông truyền thống chủ yếu gồm:
\begin{itemize}
    \item \textbf{Điều khiển chu kỳ cố định (Fixed-time):} Thời gian các pha được thiết kế trước dựa trên dữ liệu lưu lượng lịch sử, không thích ứng được với biến động thực tế. Ưu điểm là đơn giản, dễ triển khai; nhược điểm là dễ gây lãng phí hoặc tắc nghẽn khi lưu lượng thay đổi \cite{Webster1958, Urbanik2015}.
    \item \textbf{Điều khiển kích hoạt (Actuated):} Sử dụng cảm biến để phát hiện xe, điều chỉnh thời gian pha trong giới hạn định trước. Linh hoạt hơn, nhưng vẫn bị giới hạn bởi các tham số cứng \cite{Koonce2008}.
    \item \textbf{Điều khiển phối hợp (Coordinated):} Đồng bộ nhiều nút giao để tạo “làn sóng xanh”. Điển hình là hệ SCOOT, SCATS. Hiệu quả trên các tuyến chính, nhưng phức tạp khi áp dụng cho mạng lưới lớn \cite{Hunt1981, Lowrie1990}.
\end{itemize}

\section{Hệ thống điều khiển thích nghi, học tăng cường và phương pháp lai}

Để khắc phục hạn chế của các phương pháp truyền thống, các hệ thống thích nghi như SCOOT, SCATS, OPAC đã ra đời. Các hệ này điều chỉnh thời gian tín hiệu dựa trên trạng thái giao thông thực, tăng khả năng phản ứng với biến động \cite{Eom2020}. 

Gần đây, các kỹ thuật học tăng cường (Reinforcement Learning - RL) được ứng dụng mạnh mẽ, cho phép hệ thống tự học chính sách tối ưu thông qua tương tác và phần thưởng thực tế \cite{Abdulhai2003, Li2016}. RL giúp tối ưu hóa hiệu năng tổng thể và thích nghi với nhiều kịch bản khác nhau.

Xu hướng hiện nay là kết hợp các phương pháp: điều khiển luật, thích nghi và học máy (hybrid). Việc phối hợp này tận dụng ưu điểm từng cách tiếp cận, đảm bảo hệ thống vừa an toàn, vừa tối ưu hóa linh hoạt trong điều kiện phức tạp \cite{Wei2019}.

\section{Khoảng trống nghiên cứu}

Mặc dù có nhiều tiến bộ, vẫn tồn tại các vấn đề cần giải quyết:
\begin{itemize}
    \item \textbf{Khả năng mở rộng hạn chế:} RL truyền thống (Q-learning) khó khái quát cho mạng lưới lớn, thiếu hàm xấp xỉ như mạng nơ-ron sâu \cite{Li2016, Liang2019}.
    \item \textbf{Đánh giá chưa toàn diện:} Nhiều nghiên cứu thiếu benchmark chuẩn, kiểm định thống kê và phân tích đa chiều các chỉ số \cite{Shaikh2022}.
    \item \textbf{Phối hợp đa nút giao:} Ít giải pháp cho multi-agent coordination, chưa tối ưu cho mạng lưới lớn với độ trễ giao tiếp thực tế \cite{Kouvelas2011}.
    \item \textbf{Sim-to-real gap:} Kết quả mô phỏng khó chuyển giao sang ứng dụng thực tế, thiếu tích hợp cảm biến thực và domain randomization \cite{Lopez2018}.
    \item \textbf{Thiết kế reward và công bằng:} Hàm thưởng thường phức tạp, chưa phân tích ảnh hưởng các thành phần tới kết quả, khó đảm bảo fairness giữa các hướng giao thông \cite{Sutton2018}.
    \item \textbf{Đảm bảo an toàn:} Thiếu kiểm thử stress với các tình huống cực đoan, thiếu cơ chế xác minh ràng buộc cứng \cite{Mirchandani2001}.
\end{itemize}

\section{Kết luận chương}

Nhu cầu phát triển hệ thống điều khiển tín hiệu giao thông thông minh vẫn còn nhiều thách thức: khả năng mở rộng, phối hợp đa nút, chuyển giao thực tế, đánh giá chuẩn, và đảm bảo an toàn. Luận văn này hướng tới giải quyết một phần các khoảng trống trên bằng cách phát triển bộ điều khiển lai APC-RL với cơ chế ưu tiên, quản lý tắc nghẽn, rẽ trái bảo vệ và lưu trữ dữ liệu thực nghiệm đồng bộ, đặt nền móng cho các nghiên cứu mở rộng trong tương lai.